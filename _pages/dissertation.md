---
layout: default
permalink: /dissertation/
title: dissertation
description: 
years: [2023]
nav: true
nav_order: 2
---

## Towards Mixed-Initiative Machines for Creatives

My PhD dissertation research investigates how interactions can be designed so that physical machines become collaborators. I focus on machines that are used in physically creative tasks, such as drawing with pen plotters and making ceramics using clay extruders. A simple way to envision how a machine could help with drawing, is in the form of guidelines. It's easy to imagine how a machine could use its near-perfect vision and motor capabilities to guide a person towards accurate reproduction of a scene.

<img width="300" alt="vignette_guide" src="https://github.com/user-attachments/assets/ef177e22-7cb2-4996-8fee-ff80beb7b756">

In open-ended drawing and ceramics, however, determining whether the work was succesful is subjective. Oftentimes, people who perform creative tasks are in an ongoing reflection with the material at hand -- depending on how it goes, a person might decide their next action, and so on. An example of this is doodling: usually, the goal of the drawing emerges as the process unfolds.    

<img width="300" alt="vignette_presence" src="https://github.com/user-attachments/assets/2ad151c7-0ee2-4d4b-ab0d-6ee405f9fc3b">

In order to doodle alongside, or create alongside a person, a machine needs to be able to observe and act. It needs to "get" the user, see what is happening with the material, and adapt its behavior accordingly. 

<img width="300" alt="vignette_cocreator" src="https://github.com/user-attachments/assets/0bcee79b-b418-4248-84a0-d4f551bc4848">

"Getting" the user involves clear communication between the two parties. If the machine gets it wrong, the user might make a facial expression, or talk to the machine. Ideally, a smart machine should be able to do something with this input, instead of stoically continuing to do what it has been doing.

I approach this topic from an angle of *interaction design*, asking how designers can conceptualize, prototype, and test interactions. As such, I approach the problem of interaction design for physically creative machines in three steps:

#### **1. How do people interact with physically creative machines?**

In order to answer this question, designers need to be able to elicit and capture interactions around and with machines. My first research contribution thus takes the form of *methods of interaction capture*. This means that I develop and test methods that can be used by designers to gather and analyze data that allows us to understand people. Creative machines present unique challenges in this regard, meaning that out-of-the-box HCI methods of interaction capture aren't always suitable.

<img width="300" alt="placeholder_rig_pro" src="https://github.com/user-attachments/assets/6ab856c9-f0c5-4135-9a97-8b586262fd8e">

#### **2. How can designers prototype interactions *through* physically creative machines?**

One of the most common methods used for prototyping interactions with complex technologies, is Wizard-of-Oz. This method involves a researcher controlling the machine in real-time, making it seem like the machine already has the technical capability to behave in a certain way. The benefit of this method is that ideas can be tested before extensive technical implementation has taken place. It is difficult to be a wizard, and especially for creative tasks, control needs to be quick, precise and fine-grained. I *develop and test methods to perform Wizard-of-Oz* for creative machines, ranging from low-fidelity to high-fidelity methods, including various degrees of automation. These methods allow designers to try out different interaction designs, see how people react, and gradually develop them into automated behaviors of the machine.

<img height="160" alt="wizarding" src="https://github.com/user-attachments/assets/4486a54f-fbbd-4fb1-b34e-76f49d838e0a">
<img height="160" alt="woz1" src="https://github.com/user-attachments/assets/7db0db9c-e598-40de-ab9a-c90538177bd2">
<img height="160" alt="scfwoz" src="https://github.com/user-attachments/assets/233bee31-7501-46b5-9771-d69cabc66d5f">

#### **3. What are the interactive capabilities required to facilitate collaborative creative machines?**

Lastly, to make machines collaborative, I focus on *how the machines can communicate with people*. The primary modalities that I take into account are spoken communications, such as utterances and commands, and non-verbal signals that include body pose and facial expression. Communication goes in two directions: whereas the prior two steps might allow a machine to understand a person, the machine should also be able to communicate back. To achieve this, I modify creative machines to allow them to communicate back to people through voice and movement. 

<img width="300" alt="Screenshot 2024-09-18 at 12 15 49â€¯AM" src="https://github.com/user-attachments/assets/4185810d-9743-4f06-a650-863d2edc7050">
<img width="300" alt="process" src="https://github.com/user-attachments/assets/692eb239-3bfd-4744-81dd-1bb2f3285ebf">





